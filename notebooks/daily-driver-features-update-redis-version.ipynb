{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# This notebook gives a demo to load the binary classifier models built for predicting the success of an LP Attempt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "### Loading the binary_models.yaml file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import truncate\n",
    "import sys\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from pathlib import Path\n",
    "import os\n",
    "import yaml\n",
    "import h3\n",
    "\n",
    "path_root = Path(os.path.abspath('')).parents[0] / 'lib'\n",
    "sys.path.append(str(path_root))\n",
    "from ds_shared.service_level import unify_service_levels, lp_sla_time_in_minutes\n",
    "\n",
    "# Define the path where models are stored\n",
    "MODEL_FOLDER = Path().resolve().parents[0] / 'output_models'\n",
    "\n",
    "# Define the file path\n",
    "yaml_file_path = MODEL_FOLDER / \"binary_models.yaml\"\n",
    "\n",
    "# Read from a YAML file\n",
    "with open(yaml_file_path, 'r') as file:\n",
    "    yaml_data = yaml.safe_load(file)\n",
    "\n",
    "best_resolution = yaml_data['geospatial_resolution']\n",
    "\n",
    "predictors = {}\n",
    "for model_num in range(4):\n",
    "    predictors[model_num] =  yaml_data['feature_sets'][f'set{model_num}']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "### Loading all the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded models from: /Users/tariehkgeter/projects-active/lm-aspm-1-notebook-dev/output_models/model_set0.joblib\n",
      "Loaded models from: /Users/tariehkgeter/projects-active/lm-aspm-1-notebook-dev/output_models/model_set1.joblib\n",
      "Loaded models from: /Users/tariehkgeter/projects-active/lm-aspm-1-notebook-dev/output_models/model_set2.joblib\n",
      "Loaded models from: /Users/tariehkgeter/projects-active/lm-aspm-1-notebook-dev/output_models/model_set3.joblib\n"
     ]
    }
   ],
   "source": [
    "# Number of models\n",
    "n_models = len(predictors)\n",
    "all_models = {}\n",
    "\n",
    "# Load the models\n",
    "for i in range(n_models):\n",
    "    fname = 'model_set' + str(i) + '.joblib'\n",
    "    all_models[i] = joblib.load(MODEL_FOLDER / fname)\n",
    "    print(f\"Loaded models from: {MODEL_FOLDER / fname}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "# Loading the past month's data to update driver features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data!!\n",
      "THE PATH IS ../past_month\n",
      "('PROD_REPORTING_RW_AR', 'PROD_DB_V2', 'CURATED_DATA')\n",
      "completed the execution\n",
      "Combining CSVs!!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(\"Extracting data!!\")\n",
    "!{sys.executable} ../data_extraction/sf-extract-attempt-data-evenly-by-sla.py --capture_days 30 --folder_name 'past_month' --sample_rate 10\n",
    "\n",
    "print(\"Combining CSVs!!\")\n",
    "!{sys.executable} ../data_extraction/combine_csvs.py --folder_name 'past_month'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the pricing data\n",
    "DATA = Path().resolve().parents[0] / 'past_month'\n",
    "PRICING_SET = DATA / 'attempt_success_prediction_final_mi.csv'\n",
    "df_month = pd.read_csv(PRICING_SET, dtype={7: str})\n",
    "df_month = df_month.sort_values(by='dispatchedOn').reset_index(drop=True)\n",
    "df_month = df_month.drop_duplicates(subset=['attemptId'], keep=False)\n",
    "\n",
    "df_month['attemptSuccess'] = df_month.apply(lambda x: 1 if x.attemptStatus == 'DELIVERED' else 0, axis=1)\n",
    "df_month['dispatchedOn'] = pd.to_datetime(df_month['dispatchedOn'])\n",
    "\n",
    "df_month, all_sls = unify_service_levels(df_month)\n",
    "# Including only the rows with serviceLevels in the desired modes\n",
    "df_month = df_month[df_month['serviceLevel'].isin(lp_sla_time_in_minutes.keys())]\n",
    "\n",
    "# Adding the geospatial feature\n",
    "df_month['h3_zone'] = df_month.apply(lambda row: h3.latlng_to_cell(row.fromLat, row.fromLon, best_resolution), axis=1).astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "past_1mo_stats = df_month.groupby('lpOrganizationId').agg(\n",
    "    past_1mo_attempts=('attemptSuccess', 'size'),\n",
    "    past_1mo_success=('attemptSuccess', 'sum')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['deliveryId', 'attemptId', 'lpOrganizationId', 'attemptNumber',\n",
       "       'deliveryStatus', 'attemptStatus', 'shipperCost', 'serviceLevel',\n",
       "       'dispatchedOn', 'distanceMi', 'weightLbsTotal', 'largestWeightLbs',\n",
       "       'sizeCuInTotal', 'largestDimIn', 'secondDimIn', 'thirdDimIn',\n",
       "       'itemCount', 'fromLat', 'fromLon', 'toLat', 'toLon', 'stateCode',\n",
       "       'NETWORK_TYPE', 'SHIPPER_CONTRACT_SLA_ID', 'attemptSuccess', 'h3_zone'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_month.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e5ed5ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>past_1mo_attempts</th>\n",
       "      <th>past_1mo_success</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lpOrganizationId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0274e9a2-7d49-4607-bdfe-bf058ff8d4e5</th>\n",
       "      <td>51</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0323cd0e-23fb-4959-8587-51761336a435</th>\n",
       "      <td>81</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>05848181-3122-4207-a46e-0ec29ee944bd</th>\n",
       "      <td>1142</td>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>060b25cd-4e91-4928-90a7-51859f061c59</th>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>063a6987-7c21-4c9f-8473-a80b9382b925</th>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e9606baf-834f-4ab2-a06b-5ce8ba60d8af</th>\n",
       "      <td>27</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ed002bcd-a64d-4b2e-a81b-734e3a83fcf7</th>\n",
       "      <td>557</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f070aa38-48ab-4ef2-a2ac-c88914b02981</th>\n",
       "      <td>247</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f3a11bfe-41ce-48ec-9136-0b22e12b1925</th>\n",
       "      <td>3941</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fdd77b2c-85ca-4458-9d94-59a41332dfcd</th>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>74 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      past_1mo_attempts  past_1mo_success\n",
       "lpOrganizationId                                                         \n",
       "0274e9a2-7d49-4607-bdfe-bf058ff8d4e5                 51                 4\n",
       "0323cd0e-23fb-4959-8587-51761336a435                 81                 0\n",
       "05848181-3122-4207-a46e-0ec29ee944bd               1142               169\n",
       "060b25cd-4e91-4928-90a7-51859f061c59                 24                 2\n",
       "063a6987-7c21-4c9f-8473-a80b9382b925                 26                 1\n",
       "...                                                 ...               ...\n",
       "e9606baf-834f-4ab2-a06b-5ce8ba60d8af                 27                 4\n",
       "ed002bcd-a64d-4b2e-a81b-734e3a83fcf7                557                21\n",
       "f070aa38-48ab-4ef2-a2ac-c88914b02981                247                 2\n",
       "f3a11bfe-41ce-48ec-9136-0b22e12b1925               3941                35\n",
       "fdd77b2c-85ca-4458-9d94-59a41332dfcd                 22                 0\n",
       "\n",
       "[74 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "past_1mo_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883a93c4",
   "metadata": {},
   "source": [
    "# Moving the past month attempts and success to Redis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c429a0e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: redis in /Users/tariehkgeter/projects-active/lm-aspm-1-notebook-play/.venv/lib/python3.11/site-packages (6.4.0)\n",
      "Requirement already satisfied: python-dotenv in /Users/tariehkgeter/projects-active/lm-aspm-1-notebook-play/.venv/lib/python3.11/site-packages (1.1.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "✅ Connected to Redis at onerail-data-science-staging.redis.cache.windows.net\n"
     ]
    }
   ],
   "source": [
    "# We are going to use Redis to store the field: past_1mo_attemppts and past_1mo_success\n",
    "# If you don't have it installed, run the following command:\n",
    "%pip install redis python-dotenv\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "import redis\n",
    "\n",
    "# Load the .env that lives in data_extraction/\n",
    "load_dotenv(Path(\"..\") / \"data_extraction\" / \".env\")  \n",
    "# Now REDIS_HOST, REDIS_PORT, REDIS_KEY are in os.environ\n",
    "\n",
    "# Build the Redis client (SSL only)\n",
    "redis_client = redis.StrictRedis(\n",
    "    host=os.getenv(\"REDIS_HOST\"),\n",
    "    port=int(os.getenv(\"REDIS_PORT\")),\n",
    "    password=os.getenv(\"REDIS_KEY\"),\n",
    "    ssl=True\n",
    ")\n",
    "\n",
    "print(\"✅ Connected to Redis at\", os.getenv(\"REDIS_HOST\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e6b1d379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Seeded Redis with 74 LP records\n"
     ]
    }
   ],
   "source": [
    "# ─── 3) Seed Redis ──────────\n",
    "# Since lpOrganizationId is the index, we need to iterate through the DataFrame differently\n",
    "for lp, row in past_1mo_stats.iterrows():\n",
    "    attempts = int(row.past_1mo_attempts)\n",
    "    successes = int(row.past_1mo_success)\n",
    "\n",
    "    # Store two keys for each LP\n",
    "    redis_client.set(f\"lpOrganizationId:{lp}:past_1mo_total_attempts\", attempts)\n",
    "    redis_client.set(f\"lpOrganizationId:{lp}:past_1mo_success\", successes)\n",
    "\n",
    "print(f\"✅ Seeded Redis with {len(past_1mo_stats)} LP records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88e1e54c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verifying Redis data for 3 random LP organizations:\n",
      "----------------------------------------------------------------------\n",
      "LP ID: 71b4384b-4c14-471e-8a06-1045feef95a1\n",
      "Redis:     total= 285  success=   4\n",
      "DataFrame: total= 285  success=   4\n",
      "Redis Key: lpOrganizationId:71b4384b-4c14-471e-8a06-1045feef95a1:past_1mo_success  Redis Value: 4\n",
      "----------------------------------------------------------------------\n",
      "LP ID: 38224777-cc12-4271-b29e-d61f1d8e108f\n",
      "Redis:     total=   8  success=   0\n",
      "DataFrame: total=   8  success=   0\n",
      "Redis Key: lpOrganizationId:38224777-cc12-4271-b29e-d61f1d8e108f:past_1mo_success  Redis Value: 0\n",
      "----------------------------------------------------------------------\n",
      "LP ID: 6a126a25-a8dc-4f10-a8af-e3c0ee540cd6\n",
      "Redis:     total=  77  success=   0\n",
      "DataFrame: total=  77  success=   0\n",
      "Redis Key: lpOrganizationId:6a126a25-a8dc-4f10-a8af-e3c0ee540cd6:past_1mo_success  Redis Value: 0\n",
      "----------------------------------------------------------------------\n",
      "✅ Verification complete: Redis data matches DataFrame values\n"
     ]
    }
   ],
   "source": [
    "# ─── 4) Verify Redis contents ──────────\n",
    "import random\n",
    "\n",
    "# Get a list of LPs from the index of past_1mo_stats\n",
    "sample_lps = random.sample(list(past_1mo_stats.index), k=3)\n",
    "print(\"Verifying Redis data for 3 random LP organizations:\")\n",
    "print(\"-\" * 70)\n",
    "for lp in sample_lps:\n",
    "    # Get values from Redis\n",
    "    t = redis_client.get(f\"lpOrganizationId:{lp}:past_1mo_total_attempts\")\n",
    "    s = redis_client.get(f\"lpOrganizationId:{lp}:past_1mo_success\")\n",
    "    \n",
    "    # Get values from DataFrame for comparison\n",
    "    df_total = past_1mo_stats.loc[lp, 'past_1mo_attempts'] \n",
    "    df_success = past_1mo_stats.loc[lp, 'past_1mo_success']\n",
    "    \n",
    "    # Display in a more readable format\n",
    "    print(f\"LP ID: {lp}\")\n",
    "    print(f\"Redis:     total={int(t or 0):4}  success={int(s or 0):4}\")\n",
    "    print(f\"DataFrame: total={df_total:4}  success={df_success:4}\")\n",
    "    \n",
    "    # Show the actual Redis keys and values\n",
    "    # print(f\"Redis Key: lpOrganizationId:{lp}:past_1mo_total_attempts    Redis Value: {t.decode('utf-8') if t else 0}\")\n",
    "\n",
    "    print(f\"Redis Key: lpOrganizationId:{lp}:past_1mo_success  Redis Value: {s.decode('utf-8') if s else 0}\")\n",
    "    print(\"-\" * 70)\n",
    "\n",
    "print(\"✅ Verification complete: Redis data matches DataFrame values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "# Testing on sample raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample test data\n",
    "path_root = Path(os.path.abspath('')).parents[0] / 'lib'\n",
    "sys.path.append(str(path_root))\n",
    "from ds_shared.service_level import unify_service_levels\n",
    "\n",
    "# Create a new row as a dictionary\n",
    "raw_data = {'distanceMi': 50, 'weightLbsTotal': 0, 'largestDimIn': 0, 'secondDimIn': 0, 'thirdDimIn': 0, 'largestWeightLbs': 0, 'serviceLevel': '1 Minute', 'fromLat': 32, 'fromLon': -90, 'lpOrganizationId':'16b6c714-f8d7-4a81-9ac2-a3938f3450c2'}\n",
    "\n",
    "X_test = pd.DataFrame([raw_data])\n",
    "X_test, all_sls = unify_service_levels(X_test)\n",
    "\n",
    "#X_test['serviceLevel'].isin(lp_sla_time_in_minutes.keys())\n",
    "\n",
    "X_test['h3_zone'] = X_test.apply(lambda x: h3.latlng_to_cell(x.fromLat, x.fromLon, best_resolution), axis=1).astype('category')\n",
    "X_test['past_1mo_total_attempts'] = X_test.apply(lambda x: past_1mo_stats.past_1mo_attempts.get(x.lpOrganizationId, 0), axis=1)\n",
    "X_test['past_1mo_successes'] = X_test.apply(lambda x: past_1mo_stats.past_1mo_success.get(x.lpOrganizationId, 0), axis=1)\n",
    "\n",
    "\n",
    "# This is the check for a single instance, do modify when you have multiple rows\n",
    "if(X_test['serviceLevel'].isin(lp_sla_time_in_minutes.keys()).loc[0]):\n",
    "    if(('secondDimIn' in X_test.columns) and ('thirdDimIn' in X_test.columns)):\n",
    "        model_num = 3\n",
    "    else:\n",
    "        model_num = 1\n",
    "else:\n",
    "    if(('secondDimIn' in X_test.columns) and ('thirdDimIn' in X_test.columns)):\n",
    "        model_num = 2\n",
    "    else:\n",
    "        model_num = 0\n",
    "\n",
    "print('For teh above set of features using model#{} and its prediction is {}'.format(model_num, all_models[model_num].predict(X_test[predictors[model_num]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
