{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# This notebook gives a demo to load the binary classifier models and calculate the daily evaluation metrics of the model for drift"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "### Loading the binary_models.yaml file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import truncate\n",
    "import sys\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from pathlib import Path\n",
    "import os\n",
    "import yaml\n",
    "import h3\n",
    "\n",
    "path_root = Path(os.path.abspath('')).parents[0] / 'lib'\n",
    "sys.path.append(str(path_root))\n",
    "from ds_shared.service_level import unify_service_levels, lp_sla_time_in_minutes\n",
    "\n",
    "# Define the path where models are stored\n",
    "MODEL_FOLDER = Path().resolve().parents[0] / 'output_models'\n",
    "\n",
    "# Define the file path\n",
    "yaml_file_path = MODEL_FOLDER / \"binary_models.yaml\"\n",
    "\n",
    "# Read from a YAML file\n",
    "with open(yaml_file_path, 'r') as file:\n",
    "    yaml_data = yaml.safe_load(file)\n",
    "\n",
    "best_resolution = yaml_data['geospatial_resolution']\n",
    "\n",
    "predictors = {}\n",
    "for model_num in range(4):\n",
    "    predictors[model_num] =  yaml_data['feature_sets'][f'set{model_num}']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "### Loading all the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded models from: /Users/tariehkgeter/projects-active/lm-aspm-1-notebook-play/output_models/model_set0.joblib\n",
      "Loaded models from: /Users/tariehkgeter/projects-active/lm-aspm-1-notebook-play/output_models/model_set1.joblib\n",
      "Loaded models from: /Users/tariehkgeter/projects-active/lm-aspm-1-notebook-play/output_models/model_set2.joblib\n",
      "Loaded models from: /Users/tariehkgeter/projects-active/lm-aspm-1-notebook-play/output_models/model_set3.joblib\n"
     ]
    }
   ],
   "source": [
    "# Number of models\n",
    "n_models = len(predictors)\n",
    "all_models = {}\n",
    "\n",
    "# Load the models\n",
    "for i in range(n_models):\n",
    "    fname = 'model_set' + str(i) + '.joblib'\n",
    "    all_models[i] = joblib.load(MODEL_FOLDER / fname)\n",
    "    print(f\"Loaded models from: {MODEL_FOLDER / fname}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "### Loading the last day's data for evaluating metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data!!\n",
      "THE PATH IS ../daily_data\n",
      "('PROD_REPORTING_RW_AR', 'PROD_DB_V2', 'CURATED_DATA')\n",
      "completed the execution\n",
      "Combining CSVs!!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(\"Extracting data!!\")\n",
    "!{sys.executable} ../data_extraction/sf-extract-attempt-data-evenly-by-sla.py --capture_days 1 --folder_name 'daily_data' --sample_rate 10\n",
    "\n",
    "print(\"Combining CSVs!!\")\n",
    "!{sys.executable} ../data_extraction/combine_csvs.py --folder_name 'daily_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the pricing data\n",
    "DATA = Path().resolve().parents[0] / 'daily_data'\n",
    "PRICING_SET = DATA / 'attempt_success_prediction_final_mi.csv'\n",
    "df_day = pd.read_csv(PRICING_SET, dtype={7: str})\n",
    "df_day = df_day.sort_values(by='dispatchedOn').reset_index(drop=True)\n",
    "df_day = df_day.drop_duplicates(subset=['attemptId'], keep=False)\n",
    "df_day, all_sls = unify_service_levels(df_day)\n",
    "\n",
    "df_day['attemptSuccess'] = df_day.apply(lambda x: 1 if x.attemptStatus == 'DELIVERED' else 0, axis=1)\n",
    "df_day['dispatchedOn'] = pd.to_datetime(df_day['dispatchedOn'])\n",
    "\n",
    "# Including only the rows with serviceLevels in the desired modes\n",
    "df_day = df_day[df_day['serviceLevel'].isin(lp_sla_time_in_minutes.keys())]\n",
    "\n",
    "# Adding the geospatial feature\n",
    "df_day['h3_zone'] = df_day.apply(lambda row: h3.latlng_to_cell(row.fromLat, row.fromLon, best_resolution), axis=1).astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "# Change this block to extract the measures from redis as it already has Past 1 month driver features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data!!\n",
      "THE PATH IS ../past_month\n",
      "('PROD_REPORTING_RW_AR', 'PROD_DB_V2', 'CURATED_DATA')\n",
      "completed the execution\n",
      "Combining CSVs!!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(\"Extracting data!!\")\n",
    "!{sys.executable} ../data_extraction/sf-extract-attempt-data-evenly-by-sla.py --capture_days 31 --folder_name 'past_month' --sample_rate 10\n",
    "\n",
    "print(\"Combining CSVs!!\")\n",
    "!{sys.executable} ../data_extraction/combine_csvs.py --folder_name 'past_month'\n",
    "\n",
    "# Loading the pricing data\n",
    "DATA = Path().resolve().parents[0] / 'past_month'\n",
    "PRICING_SET = DATA / 'attempt_success_prediction_final_mi.csv'\n",
    "df_month = pd.read_csv(PRICING_SET, dtype={7: str})\n",
    "df_month = df_month.sort_values(by='dispatchedOn').reset_index(drop=True)\n",
    "df_month = df_month.drop_duplicates(subset=['attemptId'], keep=False)\n",
    "df_month, all_sls = unify_service_levels(df_month)\n",
    "\n",
    "\n",
    "df_month['attemptSuccess'] = df_month.apply(lambda x: 1 if x.attemptStatus == 'DELIVERED' else 0, axis=1)\n",
    "df_month['dispatchedOn'] = pd.to_datetime(df_month['dispatchedOn'])\n",
    "\n",
    "# Including only the rows with serviceLevels in the desired modes\n",
    "df_month = df_month[df_month['serviceLevel'].isin(lp_sla_time_in_minutes.keys())]\n",
    "\n",
    "# Adding the geospatial feature\n",
    "df_month['h3_zone'] = df_month.apply(lambda row: h3.latlng_to_cell(row.fromLat, row.fromLon, best_resolution), axis=1).astype('category')\n",
    "\n",
    "# Now this would get the past month's data with respect to the past day's data\n",
    "df_month = df_month.merge(df_day, how='outer', indicator=True).query('_merge == \"left_only\"').drop(columns=['_merge'])\n",
    "\n",
    "past_1mo_stats = df_month.groupby('lpOrganizationId').agg(\n",
    "    past_1mo_attempts=('attemptSuccess', 'size'),\n",
    "    past_1mo_success=('attemptSuccess', 'sum')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "# Daily eval metrics for different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_day['past_1mo_total_attempts'] = df_day.apply(lambda x: past_1mo_stats.past_1mo_attempts.get(x.lpOrganizationId, 0), axis=1)\n",
    "df_day['past_1mo_successes'] = df_day.apply(lambda x: past_1mo_stats.past_1mo_success.get(x.lpOrganizationId, 0), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, recall_score\n",
    "\n",
    "daily_accuracy = {}\n",
    "daily_sensitivity = {}\n",
    "\n",
    "y_test = df_day['attemptSuccess']\n",
    "\n",
    "for model_num in range(len(predictors)):\n",
    "    preds = all_models[model_num].predict(df_day[predictors[model_num]]) >= yaml_data['decision_boundary'][f'model_set{model_num}']\n",
    "    daily_accuracy[model_num] = np.round(accuracy_score(y_test, preds), 4)\n",
    "    daily_sensitivity[model_num] = np.round(recall_score(y_test, preds), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Step 1: Reformat daily_eval into rows for (date, q)\n",
    "records = []\n",
    "today = datetime.today().date()\n",
    "\n",
    "# Assuming 4 models: 0,1,2,3\n",
    "\n",
    "row = {'date': today}\n",
    "for model_num in range(4):\n",
    "    row[f'accuracy_set{model_num}'] = daily_accuracy.get((model_num), None)\n",
    "    row[f'sensitivity_set{model_num}'] = daily_sensitivity.get((model_num), None)\n",
    "    model_name = f'model_set{model_num}'\n",
    "    row[f'drift_set{model_num}'] = (daily_accuracy[(model_num)] < yaml_data['drift_detection']['accuracy_condition']['thresholds'][f'model_set{model_num}']) or (daily_sensitivity[(model_num)] < yaml_data['drift_detection']['sensitivity_condition']['thresholds'][f'model_set{model_num}'])\n",
    "records.append(row)\n",
    "\n",
    "df_daily = pd.DataFrame(records)\n",
    "# Step 2: Append to CSV log\n",
    "log_path = Path().resolve().parents[0] / 'output_models'/'model_eval_log.csv'\n",
    "\n",
    "if log_path.exists():\n",
    "    df_log = pd.read_csv(log_path)\n",
    "    df_log = pd.concat([df_log, df_daily], ignore_index=True)\n",
    "else:\n",
    "    df_log = df_daily\n",
    "\n",
    "df_log.to_csv(log_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (lm-aspm-1-notebook-play)",
   "language": "python",
   "name": "lm-aspm-1-notebook-play"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
